{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "**Probelm Statement:** Make a classifier which takes in a job description and gives the department name for it.\n",
    "*   Use a neural network model\n",
    "*   Make use of a pre-trained Word Embeddings (example: Word2Vec, GloVe, etc.)\n",
    "*   Calculate the accuracy on a test set (data not used to train the model)\n",
    "\n",
    "**Problem Solving Approach:** \n",
    "_Provide a brief description of steps you followed for solving this problem_\n",
    "1. Visualise the dataset to understand it\n",
    "2. Create a Neural Network model and check its accuracy.\n",
    "3. Use pre-trained model (GloVe) and check that's accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Text Preprocessing\n",
    "\n",
    "_Include all text preprocesing steps like processing of json,csv files & data cleaning in this part._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import neccessary packages in below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_json = 'Spotmentor/data/docs'\n",
    "path_csv = 'Spotmentor/data'\n",
    "file_csv = os.path.join(path_csv, 'document_departments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['company_info', 'api_data', 'other_details', 'topbox_information', 'jd_information', '_id'])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj = json.load(open(os.path.join(path_json, str(data['Document ID'][62]) + '.json')))\n",
    "obj.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Exploratoty Data Analysis\n",
    "\n",
    "_Include EDA steps like finding distribution of Departments in this part, you may also use plots for EDA._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data['count'] = data['Department'].map(lambda c_row: 1 if isinstance(c_row, str) else 0)\n",
    "img_id = data.groupby('Department').agg({'count': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "depart_map = {}\n",
    "for i in range(len(img_id)):\n",
    "    depart_map[img_id['Department'][i]] = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f30e5afd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pos = np.arange(len(img_id))\n",
    "objects = img_id['Department']\n",
    "performance = img_id['count']\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Jobs')\n",
    "plt.title('Departments/Jobs')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = len(data)\n",
    "label = []\n",
    "keyword = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "    obj = json.load(open(os.path.join(path_json, str(data['Document ID'][i]) + '.json')))\n",
    "    department = obj['other_details']['Department:']\n",
    "    title = obj['api_data']['job_title']\n",
    "    obj = obj['api_data']['job_keywords']\n",
    "    st = [st.strip(' ') for st in obj]\n",
    "    dp = [dp.strip(' ') for dp in department]\n",
    "    tt = [tt.strip(' ') for tt in title]\n",
    "    st = st + dp + tt\n",
    "    str_join = \",\".join(st)\n",
    "    label.append(depart_map[data['Department'][i]])\n",
    "    keyword.append(str_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>keyword</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>telesales,telemarketing,communication,call cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>internet media,facebook marketing,online adver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>immigration,canada pr,australia pr,client serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>documentation,,Back Office Operations,F,r,e,s,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>internet media,facebook marketing,online adver...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                            keyword\n",
       "0      6  telesales,telemarketing,communication,call cen...\n",
       "1      8  internet media,facebook marketing,online adver...\n",
       "2     28  immigration,canada pr,australia pr,client serv...\n",
       "3      4  documentation,,Back Office Operations,F,r,e,s,...\n",
       "4      8  internet media,facebook marketing,online adver..."
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(label, columns=['label'])\n",
    "df2 = pd.DataFrame(keyword, columns=['keyword'])\n",
    "df = df.merge(df2, left_index=True, right_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df['keyword'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Modelling & Evaluation\n",
    "\n",
    "_Include all model prepration & evaluation steps in this part._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hotencode(arr):\n",
    "    a = np.zeros([len(arr), np.max(arr)])\n",
    "    for i in range(len(arr)):\n",
    "        col = arr[i]\n",
    "        a[i,col-1] = 1\n",
    "    return a\n",
    "\n",
    "def hotdecode(arr):\n",
    "    a = []\n",
    "    for i in range(len(arr)):\n",
    "        a.append(np.argmax(arr[i,:])+1)\n",
    "    return np.asarray(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "X_train = tokenizer.texts_to_sequences(x_train)\n",
    "X_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = hotencode(y_train)\n",
    "y_test_hot = hotencode(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, 100, 50)           66700     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 5000)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 35)                175035    \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 30)                1080      \n",
      "=================================================================\n",
      "Total params: 242,815.0\n",
      "Trainable params: 242,815.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=maxlen))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(35, activation='relu'))\n",
    "model.add(layers.Dense(30, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 871 samples, validate on 291 samples\n",
      "Epoch 1/30\n",
      "871/871 [==============================] - 0s - loss: 2.7971 - acc: 0.2113 - val_loss: 2.3638 - val_acc: 0.3024\n",
      "Epoch 2/30\n",
      "871/871 [==============================] - 0s - loss: 2.1572 - acc: 0.2974 - val_loss: 1.8953 - val_acc: 0.3024\n",
      "Epoch 3/30\n",
      "871/871 [==============================] - 0s - loss: 1.7487 - acc: 0.2974 - val_loss: 1.6350 - val_acc: 0.3024\n",
      "Epoch 4/30\n",
      "871/871 [==============================] - 0s - loss: 1.3381 - acc: 0.2974 - val_loss: 1.4154 - val_acc: 0.3024\n",
      "Epoch 5/30\n",
      "871/871 [==============================] - 0s - loss: 0.9007 - acc: 0.5488 - val_loss: 0.9451 - val_acc: 0.7766\n",
      "Epoch 6/30\n",
      "871/871 [==============================] - 0s - loss: 0.3887 - acc: 0.9047 - val_loss: 0.8133 - val_acc: 0.8110\n",
      "Epoch 7/30\n",
      "871/871 [==============================] - 0s - loss: 0.2154 - acc: 0.9529 - val_loss: 0.8037 - val_acc: 0.7973\n",
      "Epoch 8/30\n",
      "871/871 [==============================] - 0s - loss: 0.1170 - acc: 0.9828 - val_loss: 0.7915 - val_acc: 0.8041\n",
      "Epoch 9/30\n",
      "871/871 [==============================] - 0s - loss: 0.0747 - acc: 0.9920 - val_loss: 0.8237 - val_acc: 0.8247\n",
      "Epoch 10/30\n",
      "871/871 [==============================] - 0s - loss: 0.0487 - acc: 0.9954 - val_loss: 0.8374 - val_acc: 0.8110\n",
      "Epoch 11/30\n",
      "871/871 [==============================] - 0s - loss: 0.0351 - acc: 0.9966 - val_loss: 0.8136 - val_acc: 0.7938\n",
      "Epoch 12/30\n",
      "871/871 [==============================] - 0s - loss: 0.0281 - acc: 0.9966 - val_loss: 0.8831 - val_acc: 0.8041\n",
      "Epoch 13/30\n",
      "871/871 [==============================] - 0s - loss: 0.0175 - acc: 1.0000 - val_loss: 0.8670 - val_acc: 0.8213\n",
      "Epoch 14/30\n",
      "871/871 [==============================] - 0s - loss: 0.0130 - acc: 1.0000 - val_loss: 0.8597 - val_acc: 0.8110\n",
      "Epoch 15/30\n",
      "871/871 [==============================] - 0s - loss: 0.0120 - acc: 0.9977 - val_loss: 0.8826 - val_acc: 0.8007\n",
      "Epoch 16/30\n",
      "871/871 [==============================] - 0s - loss: 0.0105 - acc: 0.9989 - val_loss: 0.9036 - val_acc: 0.8213\n",
      "Epoch 17/30\n",
      "871/871 [==============================] - 0s - loss: 0.0087 - acc: 0.9989 - val_loss: 0.8886 - val_acc: 0.8213\n",
      "Epoch 18/30\n",
      "871/871 [==============================] - 0s - loss: 0.0060 - acc: 1.0000 - val_loss: 0.8867 - val_acc: 0.8247\n",
      "Epoch 19/30\n",
      "871/871 [==============================] - 0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.8905 - val_acc: 0.8247\n",
      "Epoch 20/30\n",
      "871/871 [==============================] - 0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.9006 - val_acc: 0.8213\n",
      "Epoch 21/30\n",
      "871/871 [==============================] - 0s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.9055 - val_acc: 0.8213\n",
      "Epoch 22/30\n",
      "871/871 [==============================] - 0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.9185 - val_acc: 0.8213\n",
      "Epoch 23/30\n",
      "871/871 [==============================] - 0s - loss: 0.0027 - acc: 1.0000 - val_loss: 0.9268 - val_acc: 0.8179\n",
      "Epoch 24/30\n",
      "871/871 [==============================] - 0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.9268 - val_acc: 0.8213\n",
      "Epoch 25/30\n",
      "871/871 [==============================] - 0s - loss: 0.0019 - acc: 1.0000 - val_loss: 0.9359 - val_acc: 0.8213\n",
      "Epoch 26/30\n",
      "871/871 [==============================] - 0s - loss: 0.0017 - acc: 1.0000 - val_loss: 0.9384 - val_acc: 0.8213\n",
      "Epoch 27/30\n",
      "871/871 [==============================] - 0s - loss: 0.0016 - acc: 1.0000 - val_loss: 0.9491 - val_acc: 0.8179\n",
      "Epoch 28/30\n",
      "871/871 [==============================] - 0s - loss: 0.0014 - acc: 1.0000 - val_loss: 0.9559 - val_acc: 0.8179\n",
      "Epoch 29/30\n",
      "871/871 [==============================] - 0s - loss: 0.0012 - acc: 1.0000 - val_loss: 0.9598 - val_acc: 0.8213\n",
      "Epoch 30/30\n",
      "871/871 [==============================] - 0s - loss: 0.0011 - acc: 1.0000 - val_loss: 0.9697 - val_acc: 0.8144\n",
      "Training Accuracy: 1.0000\n",
      "Testing Accuracy:  0.8144\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_hot, epochs=30, verbose=True, validation_data=(X_test, y_test_hot), batch_size=10)\n",
    "loss, accuracy = model.evaluate(X_train, y_train_hot, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test_hot, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using GloVe\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def create_embedding_matrix(filepath, word_index, embedding_dim):\n",
    "    vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
    "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "    with open(filepath, encoding=\"utf8\") as f:\n",
    "        for line in f:\n",
    "            word, *vector = line.split()\n",
    "            if word in word_index:\n",
    "                idx = word_index[word] \n",
    "                embedding_matrix[idx] = np.array(vector, dtype=np.float32)[:embedding_dim]\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 50\n",
    "embedding_matrix = create_embedding_matrix('Spotmentor/glove.6B/glove.6B.50d.txt',tokenizer.word_index, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 100, 50)           66700     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 35)                1785      \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 30)                1080      \n",
      "=================================================================\n",
      "Total params: 69,565.0\n",
      "Trainable params: 69,565.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Embedding(vocab_size, embedding_dim, weights=[embedding_matrix], input_length=maxlen, trainable=True))\n",
    "model.add(layers.GlobalMaxPool1D())\n",
    "model.add(layers.Dense(35, activation='relu'))\n",
    "model.add(layers.Dense(30, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 871 samples, validate on 291 samples\n",
      "Epoch 1/30\n",
      "871/871 [==============================] - 0s - loss: 2.8228 - acc: 0.2204 - val_loss: 2.2820 - val_acc: 0.2715\n",
      "Epoch 2/30\n",
      "871/871 [==============================] - 0s - loss: 2.2725 - acc: 0.2262 - val_loss: 2.1550 - val_acc: 0.2371\n",
      "Epoch 3/30\n",
      "871/871 [==============================] - 0s - loss: 2.1879 - acc: 0.2537 - val_loss: 2.0971 - val_acc: 0.3127\n",
      "Epoch 4/30\n",
      "871/871 [==============================] - 0s - loss: 2.1296 - acc: 0.3008 - val_loss: 2.0854 - val_acc: 0.3024\n",
      "Epoch 5/30\n",
      "871/871 [==============================] - 0s - loss: 2.0644 - acc: 0.2974 - val_loss: 1.9953 - val_acc: 0.3024\n",
      "Epoch 6/30\n",
      "871/871 [==============================] - 0s - loss: 1.9620 - acc: 0.2974 - val_loss: 1.8993 - val_acc: 0.3024\n",
      "Epoch 7/30\n",
      "871/871 [==============================] - 0s - loss: 1.8458 - acc: 0.3215 - val_loss: 1.7413 - val_acc: 0.5052\n",
      "Epoch 8/30\n",
      "871/871 [==============================] - 0s - loss: 1.5559 - acc: 0.5936 - val_loss: 1.3453 - val_acc: 0.6907\n",
      "Epoch 9/30\n",
      "871/871 [==============================] - 0s - loss: 1.2460 - acc: 0.6762 - val_loss: 1.1446 - val_acc: 0.7251\n",
      "Epoch 10/30\n",
      "871/871 [==============================] - 0s - loss: 1.0652 - acc: 0.7268 - val_loss: 0.9869 - val_acc: 0.7629\n",
      "Epoch 11/30\n",
      "871/871 [==============================] - 0s - loss: 0.9396 - acc: 0.7727 - val_loss: 0.9363 - val_acc: 0.7835\n",
      "Epoch 12/30\n",
      "871/871 [==============================] - 0s - loss: 0.8402 - acc: 0.8037 - val_loss: 0.8673 - val_acc: 0.7904\n",
      "Epoch 13/30\n",
      "871/871 [==============================] - 0s - loss: 0.7777 - acc: 0.8197 - val_loss: 0.8333 - val_acc: 0.7973\n",
      "Epoch 14/30\n",
      "871/871 [==============================] - 0s - loss: 0.7246 - acc: 0.8358 - val_loss: 0.7669 - val_acc: 0.8110\n",
      "Epoch 15/30\n",
      "871/871 [==============================] - 0s - loss: 0.6656 - acc: 0.8588 - val_loss: 0.7418 - val_acc: 0.8282\n",
      "Epoch 16/30\n",
      "871/871 [==============================] - 0s - loss: 0.6324 - acc: 0.8462 - val_loss: 0.7325 - val_acc: 0.8213\n",
      "Epoch 17/30\n",
      "871/871 [==============================] - 0s - loss: 0.5939 - acc: 0.8588 - val_loss: 0.6954 - val_acc: 0.8419\n",
      "Epoch 18/30\n",
      "871/871 [==============================] - 0s - loss: 0.5476 - acc: 0.8657 - val_loss: 0.6878 - val_acc: 0.8351\n",
      "Epoch 19/30\n",
      "871/871 [==============================] - 0s - loss: 0.5215 - acc: 0.8726 - val_loss: 0.6445 - val_acc: 0.8316\n",
      "Epoch 20/30\n",
      "871/871 [==============================] - 0s - loss: 0.4963 - acc: 0.8783 - val_loss: 0.6459 - val_acc: 0.8351\n",
      "Epoch 21/30\n",
      "871/871 [==============================] - 0s - loss: 0.4746 - acc: 0.8760 - val_loss: 0.6294 - val_acc: 0.8351\n",
      "Epoch 22/30\n",
      "871/871 [==============================] - 0s - loss: 0.4383 - acc: 0.8898 - val_loss: 0.6120 - val_acc: 0.8488\n",
      "Epoch 23/30\n",
      "871/871 [==============================] - 0s - loss: 0.4140 - acc: 0.8875 - val_loss: 0.5961 - val_acc: 0.8488\n",
      "Epoch 24/30\n",
      "871/871 [==============================] - 0s - loss: 0.3904 - acc: 0.8990 - val_loss: 0.5719 - val_acc: 0.8729\n",
      "Epoch 25/30\n",
      "871/871 [==============================] - 0s - loss: 0.3695 - acc: 0.9059 - val_loss: 0.5670 - val_acc: 0.8522\n",
      "Epoch 26/30\n",
      "871/871 [==============================] - 0s - loss: 0.3501 - acc: 0.9013 - val_loss: 0.5616 - val_acc: 0.8625\n",
      "Epoch 27/30\n",
      "871/871 [==============================] - 0s - loss: 0.3213 - acc: 0.9185 - val_loss: 0.5742 - val_acc: 0.8591\n",
      "Epoch 28/30\n",
      "871/871 [==============================] - 0s - loss: 0.3163 - acc: 0.9162 - val_loss: 0.5279 - val_acc: 0.8729\n",
      "Epoch 29/30\n",
      "871/871 [==============================] - 0s - loss: 0.2842 - acc: 0.9265 - val_loss: 0.5210 - val_acc: 0.8832\n",
      "Epoch 30/30\n",
      "871/871 [==============================] - 0s - loss: 0.2681 - acc: 0.9392 - val_loss: 0.5249 - val_acc: 0.8660\n",
      "Training Accuracy: 0.9311\n",
      "Testing Accuracy:  0.8660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train_hot, epochs=30, verbose=True, validation_data=(X_test, y_test_hot), batch_size=10)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_train, y_train_hot, verbose=False)\n",
    "print(\"Training Accuracy: {:.4f}\".format(accuracy))\n",
    "loss, accuracy = model.evaluate(X_test, y_test_hot, verbose=False)\n",
    "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Summary:**\n",
    "_Provide a brief summary of results obtained like model accuracy & other insights based on EDA & your interpretations_\n",
    "\n",
    "1. Maybe because of imbalance in data the accuracy is not that great.\n",
    "2. Using some transfer learning techniques like GloVe increases some accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
